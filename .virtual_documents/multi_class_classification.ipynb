import pandas as pd
import numpy as np


df = pd.read_csv("iris_synthetic_data.csv")
df.sample(5)


df.info()


df.describe()


df.isnull().sum()


X = df.iloc[:,:-1]
X


y = df.iloc[:,-1]
y


label_to_index = {label: idx for idx, label in enumerate(np.unique(y))}
index_to_label = { idx: label for label, idx in label_to_index.items()}

y = np.array([label_to_index[label] for label in y])
num_classes = len(label_to_index)


def one_hot_encoding(y, num_classes):
    one_hot_labels = np.zeros((y.size, num_classes))
    one_hot_labels[np.arange(y.size),y]=1
    return one_hot_labels

y_encoded = one_hot_encoding(y, num_classes)
y_encoded


from sklearn.model_selection import train_test_split 
X_train_val, X_test, y_train_val, y_test = train_test_split(X, y_encoded, test_size=0.15, random_state=42, stratify=y_encoded)
X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1764, random_state=42, stratify=y_train_val )


X_train, y_train


X_val, y_val


X_test, y_test


from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)
X_test = scaler.transform(X_test)
X_train, X_val, X_test


class multi_class_classification:
    def __init__(self, learning_rate = 0.01, n_iteration = 3000, beta = 0.95, epsilon = 1e-8):
        self.learning_rate = learning_rate
        self.n_iteration = n_iteration
        self.beta = beta 
        self.epsilon = epsilon
        self.weights = None
        self.bias = None
        self.losses = []
        self.v_dw = None
        self.v_db = None

    def softmax(self, z):
        exp_z = np.exp(z-np.max(z, axis = 1, keepdims = True))
        return exp_z/np.sum(exp_z, axis = 1, keepdims = True)

    def compute_cost(self, y, y_hat):
        loss = -np.sum(y*np.log(y_hat + self.epsilon))/y.shape[0]
        return loss
        
    def update_params_rms_prop(self, dw, db):
        self.v_dw = self.beta * self.v_dw + (1-self.beta) * (dw ** 2)
        self.v_db = self.beta * self.v_db + (1-self.beta) * (db ** 2)

        self.weights -= (self.learning_rate * dw )/(np.sqrt(self.v_dw + self.epsilon))
        self.bias -= (self.learning_rate * db )/(np.sqrt(self.v_db + self.epsilon))
        
    def fit(self, X, y):
        n_samples, n_features = X.shape
        self.n_classes = y.shape[1]

        self.weights = np.zeros((n_features, self.n_classes))
        self.bias = np.zeros((1, self.n_classes))

        self.v_dw = np.zeros((n_features, self.n_classes))
        self.v_db = np.zeros((1, self.n_classes))

        for i in range(self.n_iteration):
            f_wb = np.dot(X, self.weights)+self.bias
            y_hat = self.softmax(f_wb)

            dw = (1/n_samples) * np.dot(X.T, (y_hat - y))
            db = (1/n_samples) * np.sum(y_hat - y, axis=0, keepdims=True)

            loss = self.compute_cost(y, y_hat)
            self.losses.append(loss)

            self.update_params_rms_prop(dw,db)

    def predict_proba(self, X):
        f_wb = np.dot(X, self.weights)+self.bias
        return self.softmax(f_wb)

    def predict(self, X):
        proba = self.predict_proba(X)
        return np.argmax(proba, axis = 1)


model = multi_class_classification()
model.fit(X_train, y_train)


import matplotlib.pyplot as plt
plt.figure(figsize=(10, 6))
plt.plot(model.losses)
plt.title('Loss over Iterations (Custom multi_class_classification)')
plt.xlabel('Iteration')
plt.xticks()
plt.ylabel('Categorical Cross-Entropy Loss')
plt.grid(True)
plt.show()


from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns

print("\n--- Evaluation on Validation Set ---")
# Your custom model's predict method returns class indices
y_val_pred_custom = model.predict(X_val)

# y_val is one-hot encoded, so we need to get the original class indices
y_val_true_labels = np.argmax(y_val, axis=1)

val_accuracy_custom = accuracy_score(y_val_true_labels, y_val_pred_custom)
print(f"Validation Accuracy (Custom multi_class_classification): {val_accuracy_custom:.4f}")

# To get meaningful class names in classification report and confusion matrix,
# you'll need the original label names from index_to_label mapping
# (Assuming index_to_label was created earlier and is available from your preprocessing)
# Example: If index_to_label = {0: 'Iris-setosa', 1: 'Iris-versicolor', 2: 'Iris-virginica'}
class_names = [index_to_label[i] for i in sorted(index_to_label.keys())]

print(f"\nClassification Report (Custom multi_class_classification on Validation Set):\n",
      classification_report(y_val_true_labels, y_val_pred_custom, target_names=class_names))

plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(y_val_true_labels, y_val_pred_custom), annot=True, fmt='d', cmap='Blues',
            xticklabels=class_names, yticklabels=class_names)
plt.title('Validation Confusion Matrix (Custom multi_class_classification)')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()



